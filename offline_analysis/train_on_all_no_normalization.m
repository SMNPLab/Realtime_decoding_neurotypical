
%% load the defaults 
clc
clearvars
user='';
%path to fieldtrip
%path to mvpa light
%path to custom written functions
%path to subject data folder
ft_defaults;
startup_MVPA_Light;

%load the subjname and the uniquenum arrays
subjname={'01','02','03','04','05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19'};

%% combine all preproc data 

for jjj=1:numel(subjname)

    %load the preproc file for that subject and save it to a common preproc
    %file

    %preproc file can be generated by running the step3_offline_classify
    %script from the realtime codes folder 
    preproc_all{jjj}=load(['path to subject data location'  '\' subjname{jjj} '_preproc_.mat']);

    save(['path to new data location' 'preproc_all.mat'], 'preproc_all', '-v7.3')

    clearvars -except preproc_all user subjname uniquenum
end

%% load all preproc files and pull out the relevant data
%cd to data location
load(['preproc_all.mat']); % see below 

%% code for the training the classifier here

%laod the subject wise eeg and mep data and then make it into one array
for jjj=1:numel(subjname)

    %loads the detrended mep amplitudes without bad trials
    mep{jjj}=preproc_all{jjj}.preproc.mep.amplitude; % demeaned/detrended/rescaled 

    %load the subject wise downsampled eeg data with only good trials
    keep{jjj}=preproc_all{jjj}.preproc.keep; %pulled out only the good trials
    eeg{jjj}=preproc_all{jjj}.preproc.raw.all_eeg_trials(:,keep{jjj},:);

    % check that meps and features have same number of trials
    if length(mep{jjj}) ~= size(eeg{jjj},2)
        error('dimension mismatch');
    end

    %dichotomise meps and make labels for each person
    thresh{jjj}=median(mep{jjj});

    for trl=1:length(mep{jjj})
        if mep{jjj}(trl) >= thresh{jjj}
            label{jjj}(trl)=2; % high
        elseif mep{jjj}(trl) < thresh{jjj}
            label{jjj}(trl)=1; % low 
        end
    end

    % reshape downsampled eeg data for csp calculation
    raw_csp{jjj}=permute(eeg{jjj},[2,3,1]); % trial x channel x samples

end

%loop for classifier building 
numk=19; % number of folds

clearvars preproc_all

%% build the classifier
for jj=1:19

    [perf,perf_all,runtime,ki,lda,pparam_csp,dval,plabel] = manual_classify_csp_psd_train_on_all_no_normalization_modified(numk,raw_csp,label,jj);
    classify.perf=perf;
    classify.perf_all=perf_all;
    classify.runtime=runtime;
    classify.ki=ki;
    classify.lda=lda;
    classify.pparam_csp=pparam_csp;
    classify.dval_all=dval;
    classify.plabel=plabel;
    classify.test_fold=jj;

    %cd to data saving location
    save(['classify_' num2str(jj) '.mat'],'classify','-v7.3');
    
end

%% load the classify files, get the f1 scores and mep mods for the dval threshold (corresponding to each subject)

% load the classifier files
cd(['train_on_all']);

for jj=1:19

    disp(num2str(jj))

    load(['classify_' num2str(jj) '.mat']);

    %get the f1 and best performing classifier without rounding
    grid_perf=squeeze(classify.perf(jj,:,:)); % average across each fold to get featurenum x lambdaval 
    f1_nonround=max(max(grid_perf)); 
    [fk,lk]=find(grid_perf==f1_nonround); % identify indices for optimal model configuration
    lt=length(lk); % take highest lambda value to reduce overfitting
    featkeep_nonround=fk(1);
    lambdakeep_nonround=lk(lt);

    %get the f1 and best performing classifier with rounding
    grid_perf_round=round(grid_perf,2); 
    f1_round=max(max(grid_perf_round));
    [fk_round,lk_round]=find(grid_perf_round==f1_round);
    lt_round=length(lk_round);
    featkeep_round=fk_round(1);
    lambdakeep_round=lk_round(lt_round);

    % choose rounded or non rounded classifier
    if featkeep_round < featkeep_nonround && (f1_nonround - f1_round) < 0.05 
        featkeep=featkeep_round;
        lambdakeep=lambdakeep_round;
        f1=f1_round;
    else
        featkeep=featkeep_nonround;
        lambdakeep=lambdakeep_nonround;
        f1=f1_nonround;
    end

    results.f1_w_dval(jj)= f1;
    results.featkeep_w_dval(jj)= featkeep;
    results.lambdakeep_w_dval(jj)= lambdakeep;

    %get the mep amplitudes of the most confident predictions - did not use
    %any of this in manuscript 
    dval_test=classify.dval_all{featkeep,lambdakeep,jj};
    plabel_new=classify.plabel{featkeep,lambdakeep,jj};
    dval_low=dval_test(find(plabel_new==1)); % find dvals associated with low states
    dval_high=dval_test(find(plabel_new==2)); % find dvals associated with high states

    dval_low_perc=prctile(dval_low,50,"all");
    dval_high_perc=prctile(dval_high,50,"all");

    results.high_meps_dval{jj}=mep{jj}(find(dval_test<=dval_high_perc));
    results.low_meps_dval{jj}=mep{jj}(find(dval_test>=dval_low_perc));

    results.high_meps_nodval{jj}=mep{jj}(find(plabel_new==2));
    results.low_meps_nodval{jj}=mep{jj}(find(plabel_new==1));
    
    results.mod_hilo_dval{jj}= nanmean(results.high_meps_dval{jj})./nanmean(results.low_meps_dval{jj});
    results.mod_hilo_nodval{jj}= nanmean(results.high_meps_nodval{jj})./nanmean(results.low_meps_nodval{jj});
    
    %save to data sharing location
    save(['train_on_all_no_norm.mat'],'results','-v7.3');

    %get the mep mods for each of the classifiers
    clearvars -except user results subjname uniquename mep

end





